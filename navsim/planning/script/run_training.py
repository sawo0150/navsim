import logging
from pathlib import Path
from typing import Tuple

import hydra
import pytorch_lightning as pl #PyTorch Lightningì€ PyTorch ë°˜ë³µë˜ëŠ” í•™ìŠµ ì½”ë“œë¥¼ ìë™í™”í•´ì£¼ëŠ” í”„ë ˆì„ì›Œí¬
from hydra.utils import instantiate
from omegaconf import DictConfig
from torch.utils.data import DataLoader

from navsim.agents.abstract_agent import AbstractAgent
from navsim.common.dataclasses import SceneFilter
from navsim.common.dataloader import SceneLoader
from navsim.planning.training.agent_lightning_module import AgentLightningModule
from navsim.planning.training.dataset import CacheOnlyDataset, Dataset

logger = logging.getLogger(__name__)

CONFIG_PATH = "config/training"
CONFIG_NAME = "default_training"


def build_datasets(cfg: DictConfig, agent: AbstractAgent) -> Tuple[Dataset, Dataset]:
    """
    Builds training and validation datasets from omega config
    :param cfg: omegaconf dictionary
    :param agent: interface of agents in NAVSIM
    :return: tuple for training and validation dataset
    """
    # ëª©ì  : Hydra configì™€ Agentë¥¼ ë°›ì•„ì„œ, í•™ìŠµ/ê²€ì¦ìš© Dataset ê°ì²´ ë‘ ê°œë¥¼ ë§Œë“¤ì–´ ë°˜í™˜í•˜ëŠ” ê²ƒ
    # 1. SceneFilter ë§Œë“¤ê¸°
    # 2. SceneLoader ë§Œë“¤ê¸°
    # 3. Dataset ë§Œë“¤ê¸° (ì—¬ê¸°ì„œ features/targets êµ¬ì„±ë  ì¤€ë¹„)
    # 4. ìµœì¢…ì ìœ¼ë¡œ train_data, val_data ë°˜í™˜


    train_scene_filter: SceneFilter = instantiate(cfg.train_test_split.scene_filter)
    # scene_filterëŠ” ì–´ë–¤ sceneì„ í•™ìŠµ/ê²€ì¦ì— ì“¸ì§€ ê¸°ì¤€ì„ ì •í•´ì£¼ëŠ” ì—­í• 
    # ì˜ˆ:
    # ëª‡ ì´ˆ ê³¼ê±° / ë¯¸ë˜ë¥¼ ì‚¬ìš©í•  ê±´ì§€
    # ì–´ë–¤ ë¡œê·¸ ì´ë¦„ë§Œ ì‚¬ìš©í•  ê±´ì§€
    # synthetic scene í¬í•¨í•  ê±´ì§€ ë“±ë“±â€¦

    # default_training.yaml - default_common.yaml - train_test_split ì„¤ì • ì¡´ì¬í•¨
    # ì´ ì„¤ì •ì€ train_test_split: ??? ë¡œ ë˜ì–´ ìˆì–´ì„œ ì²˜ìŒ ì‹¤í–‰í• ë•Œ ë°˜ë“œì‹œ ëª…ì‹œí•´ì•¼í•¨
    # transfuser, mlp : navtrainìœ¼ë¡œ ì‚¬ìš©í•¨

    # default_training.yaml - default_common.yaml - train_test_split ì„¤ì • ì¡´ì¬í•¨
    # ì´ ì„¤ì •ì€ train_test_split: ??? ë¡œ ë˜ì–´ ìˆì–´ì„œ ì²˜ìŒ ì‹¤í–‰í• ë•Œ ë°˜ë“œì‹œ ëª…ì‹œí•´ì•¼í•¨
    # transfuser, mlp : navtrainìœ¼ë¡œ ì‚¬ìš©í•¨

    # navtrain.yaml íŒŒì¼ ì¡´ì¬í•¨ (config/common/train_test_split/navtrain.yaml)
    # defaults:
    # - scene_filter: navtrain
    # data_split: trainval

    # scene_filter: navtrainëŠ” ë˜ common/train_test_split/scene_filter/navtrain.yaml íŒŒì¼ ì¡´ì¬í•¨


    if train_scene_filter.log_names is not None:
        train_scene_filter.log_names = [
            log_name for log_name in train_scene_filter.log_names if log_name in cfg.train_logs
        ]
    else:
        train_scene_filter.log_names = cfg.train_logs

    val_scene_filter: SceneFilter = instantiate(cfg.train_test_split.scene_filter)
    if val_scene_filter.log_names is not None:
        val_scene_filter.log_names = [log_name for log_name in val_scene_filter.log_names if log_name in cfg.val_logs]
    else:
        val_scene_filter.log_names = cfg.val_logs

    data_path = Path(cfg.navsim_log_path)
    original_sensor_path = Path(cfg.original_sensor_path)

    train_scene_loader = SceneLoader(
        original_sensor_path=original_sensor_path,
        data_path=data_path,
        scene_filter=train_scene_filter,
        sensor_config=agent.get_sensor_config(),
    )

    val_scene_loader = SceneLoader(
        original_sensor_path=original_sensor_path,
        data_path=data_path,
        scene_filter=val_scene_filter,
        sensor_config=agent.get_sensor_config(),
    )

    train_data = Dataset(
        scene_loader=train_scene_loader,
        feature_builders=agent.get_feature_builders(),
        target_builders=agent.get_target_builders(),
        cache_path=cfg.cache_path,
        force_cache_computation=cfg.force_cache_computation,
    )

    val_data = Dataset(
        scene_loader=val_scene_loader,
        feature_builders=agent.get_feature_builders(),
        target_builders=agent.get_target_builders(),
        cache_path=cfg.cache_path,
        force_cache_computation=cfg.force_cache_computation,
    )

    return train_data, val_data

# hydra ëª¨ë“ˆ í™œìš©í•¨ - ë³µì¡í•œ ì„¤ì • (í•™ìŠµë¥ , ë°°ì¹˜ ì‚¬ì´ì¦ˆ, ìµœëŒ€ ì—í­ ë“±) ì‰½ê²Œ í•  ìˆ˜ ìˆìŒ
@hydra.main(config_path=CONFIG_PATH, config_name=CONFIG_NAME, version_base=None)    
# hydra config íŒŒì¼ ë°›ì•„ì˜¤ê¸° : config/training/default_training.yaml --> 
def main(cfg: DictConfig) -> None: # type hint ë¬¸ë²• : cfg íƒ€ì…ì€ DictConfig, ë¦¬í„´ê°’ì€ None
    """
    Main entrypoint for training an agent.
    :param cfg: omegaconf dictionary
    """

    pl.seed_everything(cfg.seed, workers=True) # ëª¨ë“  ëœë¤ ì‹œë“œ ê³ ì •
    logger.info(f"Global Seed set to {cfg.seed}")

    logger.info(f"Path where all results are stored: {cfg.output_dir}")

    logger.info("Building Agent")
    agent: AbstractAgent = instantiate(cfg.agent) # type hint : agentë¼ëŠ” ë³€ìˆ˜ì˜ íƒ€ì…ì€ AbstractAgent(class) or í•˜ìœ„ class!!
    # type ê°•ì œëŠ” ì•„ë‹˜
    # instantiate : hydra config íŒŒì¼ ì¤‘ agent ì„¤ì • ë¶€ë¶„ í™œìš© class ê°ì²´ ìƒì„±
    #     defaults:
    # - default_common
    # - default_evaluation
    # - default_train_val_test_log_split
    # - agent: ego_status_mlp_agent
    # - _self_
    # ì—¬ê¸°ì„œ config/agent/ego_status_mlp_agent.yaml íŒŒì¼ í™œìš©í•´ì„œ ê·¸ê±¸ ê°ì²´ë¡œ ë§Œë“¤ì–´ì¤Œ

    logger.info("Building Lightning Module")
    lightning_module = AgentLightningModule(
        agent=agent,
    )
    # PyTorch Lightningì´ í•™ìŠµì„ ìë™ìœ¼ë¡œ ê´€ë¦¬í•˜ê²Œ ë„ì™€ì£¼ëŠ” "ë¸Œë¦¿ì§€ í´ë˜ìŠ¤"
    # ğŸ§  Agent â† (wrap) â†’ LightningModule â† (í•™ìŠµ ê´€ë¦¬) â†’ Trainer
    # - PyTorch Lightningì—ì„œ í•™ìŠµ ë£¨í”„ë¥¼ ìë™í™”í•˜ë ¤ë©´ ë°˜ë“œì‹œ `LightningModule`ì„ ìƒì†í•´ì•¼í•¨
    # - ê·¸ëŸ¬ë©´ `training_step()`, `validation_step()` ë“±ì„ ì˜¤ë²„ë¼ì´ë“œí•  ìˆ˜ ìˆìŒ

    if cfg.use_cache_without_dataset:
        # ìºì‹œë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°ë§Œ í•˜ëŠ” ê²½ìš° (CacheOnlyDataset ì‚¬ìš©)
        # ì´ë¯¸ ìƒì„±ëœ feature/targetë“¤ì„ .pt íŒŒì¼ ë“±ìœ¼ë¡œ ì €ì¥í•´ë’€ê³ ,
        # ê·¸ê±¸ ë©”ëª¨ë¦¬ì— ë‹¤ì‹œ ë¡œë”©ë§Œ í•´ì„œ ì“°ëŠ” êµ¬ì¡°
        logger.info("Using cached data without building SceneLoader")
        assert (
            not cfg.force_cache_computation
        ), "force_cache_computation must be False when using cached data without building SceneLoader"
        assert (
            cfg.cache_path is not None
        ), "cache_path must be provided when using cached data without building SceneLoader"
        train_data = CacheOnlyDataset(
            cache_path=cfg.cache_path,
            feature_builders=agent.get_feature_builders(),
            target_builders=agent.get_target_builders(),
            log_names=cfg.train_logs,
        )
        val_data = CacheOnlyDataset(
            cache_path=cfg.cache_path,
            feature_builders=agent.get_feature_builders(),
            target_builders=agent.get_target_builders(),
            log_names=cfg.val_logs,
        )
    else:
        # cacheë¥¼ í•™ìŠµí• ë•Œ ì•ˆì“°ëŠ” ê²½ìš° - ê¸°ë³¸?
        logger.info("Building SceneLoader")
        train_data, val_data = build_datasets(cfg, agent)

    logger.info("Building Datasets")
    train_dataloader = DataLoader(train_data, **cfg.dataloader.params, shuffle=True)
    logger.info("Num training samples: %d", len(train_data))
    val_dataloader = DataLoader(val_data, **cfg.dataloader.params, shuffle=False)
    logger.info("Num validation samples: %d", len(val_data))

    logger.info("Building Trainer")
    trainer = pl.Trainer(**cfg.trainer.params, callbacks=agent.get_training_callbacks())
    # pytorch lightning trainer ê°ì²´ ìƒì„± : í•™ìŠµ ê³¼ì • ê´€ë¦¬
    # yaml íŒŒì¼ ì¤‘ trainer ì„¤ì • ë¶€ë¶„ í™œìš©

    logger.info("Starting Training")
    trainer.fit(
        model=lightning_module,
        train_dataloaders=train_dataloader,
        val_dataloaders=val_dataloader,
    )


if __name__ == "__main__":
    main()
