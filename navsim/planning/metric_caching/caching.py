import gc
import logging
import os
import uuid
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

from hydra.utils import instantiate
from nuplan.planning.training.experiments.cache_metadata_entry import (
    CacheMetadataEntry,
    CacheResult,
    save_cache_metadata,
)
from nuplan.planning.utils.multithreading.worker_pool import WorkerPool
from nuplan.planning.utils.multithreading.worker_utils import worker_map
from omegaconf import DictConfig

from navsim.common.dataclasses import Scene, SensorConfig
from navsim.common.dataloader import SceneFilter, SceneLoader
from navsim.planning.metric_caching.metric_cache_processor import MetricCacheProcessor
from navsim.planning.scenario_builder.navsim_scenario import NavSimScenario

logger = logging.getLogger(__name__)


def cache_scenarios(args: List[Dict[str, Union[List[str], DictConfig]]]) -> List[CacheResult]:
    """
    Performs the caching of scenario DB files in parallel.
    :param args: A list of dicts containing the following items:
        "scenario": the scenario as built by scenario_builder
        "cfg": the DictConfig to use to process the file.
    :return: A dict with the statistics of the job. Contains the following keys:
        "successes": The number of successfully processed scenarios.
        "failures": The number of scenarios that couldn't be processed.
    """

    # Define a wrapper method to help with memory garbage collection.
    # This way, everything will go out of scope, allowing the python GC to clean up after the function.
    #
    # This is necessary to save memory when running on large datasets.
    def cache_scenarios_internal(args: List[Dict[str, Union[Path, DictConfig]]]) -> List[CacheResult]:
        def cache_single_scenario(
            scene_dict: Dict[str, Any], processor: MetricCacheProcessor
        ) -> Optional[CacheMetadataEntry]:
            scene = Scene.from_scene_dict_list(
                scene_dict,
                None,
                num_history_frames=cfg.train_test_split.scene_filter.num_history_frames,
                num_future_frames=cfg.train_test_split.scene_filter.num_future_frames,
                sensor_config=SensorConfig.build_no_sensors(),
            )
            # ğŸ‘‰ ëª©ì :
            # raw frame ë°ì´í„° (scene_dict)ë¥¼ ë°›ì•„ì„œ í•˜ë‚˜ì˜ Scene ê°ì²´ë¡œ êµ¬ì„±
            # âœ… ë‚´ë¶€ì ìœ¼ë¡œ í¬í•¨ëœ ë°ì´í„°:
            #  - ego ì°¨ëŸ‰ì˜ ê³¼ê±°/ë¯¸ë˜ ìƒíƒœ
            #  - ì£¼ë³€ ê°ì²´ì˜ ìƒíƒœë“¤
            #  - GT ê²½ë¡œ ì •ë³´
            #  - ì„¼ì„œ ì •ë³´ëŠ” ì—†ìŒ (build_no_sensors())
            #  ==> ì´ ë‹¨ê³„ëŠ” ëª¨ë¸ ì¶”ë¡ ì´ ì•„ë‹ˆë¼, í‰ê°€ ê¸°ì¤€ ì •ë³´ë§Œ ìƒì„±
            #  ==> ìºì‹± ë‹¨ê³„ì—ì„œëŠ” ego GT trajectoryì™€ ì§€ë„, ê²½ë¡œ, ê°ì²´ ì •ë³´ ë“± í‰ê°€ ê¸°ì¤€ë§Œ ì¤€ë¹„í•¨
            #  ==> ëª¨ë¸ì´ ì…ë ¥ìœ¼ë¡œ ì“°ëŠ” ì„¼ì„œ ë°ì´í„°(camera, lidar, radar ë“±)ëŠ” í•„ìš” ì—†ìŒ

            scenario = NavSimScenario(
                scene,
                map_root=os.environ["NUPLAN_MAPS_ROOT"],
                map_version="nuplan-maps-v1.0",
            )
            # NavSimScenarioëŠ” Sceneì„ nuPlan í”„ë ˆì„ì›Œí¬ì˜ ì‹œë®¬ë ˆì´ì…˜ / í‰ê°€ ì‹œìŠ¤í…œì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì¸í„°í˜ì´ìŠ¤ë¡œ ë°”ê¾¸ê¸° ìœ„í•´ ì‚¬ìš©ë¨
            # nuPlanì—ì„œ í†µì¼ëœ í‰ê°€/ì‹œë®¬ë ˆì´ì…˜ ì²˜ë¦¬ ë°©ì‹ì— ë§ì¶”ê¸° ìœ„í•´ ë§Œë“  Adapter Layer

            # ğŸ§ª ì˜ˆ: ì™œ Sceneë§Œìœ¼ë¡  ë¶€ì¡±í• ê¹Œ?
            # planner_input = PlannerInput(
            #     iteration=SimulationIteration(index=0, time_point=scenario.start_time),
            #     history=...,
            #     traffic_light_data=scenario.get_traffic_light_status_at_iteration(0),
            # )
            # ì´ëŸ° ì½”ë“œì—ì„œ scenarioëŠ” ë°˜ë“œì‹œ AbstractScenarioë¥¼ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.
            # ì¦‰, get_traffic_light_status_at_iteration() ê°™ì€ ë©”ì„œë“œê°€ ë°˜ë“œì‹œ êµ¬í˜„ë¼ì•¼ í•˜ì£ .

            # â†’ Sceneì—ëŠ” ê·¸ëŸ° ë©”ì„œë“œê°€ ì—†ê¸° ë•Œë¬¸ì—, NavSimScenarioë¡œ ê°ì‹¸ì•¼ë§Œ í”Œë˜ë„ˆ/í‰ê°€ê¸°ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

            return processor.compute_and_save_metric_cache(scenario)

        def cache_single_synthetic_scenario(
            scene_path: Path, processor: MetricCacheProcessor
        ) -> Optional[CacheMetadataEntry]:
            # synthetic scenario : Original Sceneê³¼ ë‹¤ë¥´ê²Œ ë¡œê·¸ë¡œ ìƒì„±í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼ ë¡œê·¸ ê¸°ë°˜ í•©ì„± ì‹œë®¬ë ˆì´ì…˜ ëœ scenarioì„
            scene = Scene.load_from_disk(scene_path, None, SensorConfig.build_no_sensors())
            # synthetic sceneì€ .pkl.xzë¡œ ì €ì¥ëœ ë‹¨ì¼ íŒŒì¼ì„ ë””ìŠ¤í¬ì—ì„œ ì§ì ‘ ë¡œë”©í•¨ (load_from_disk)
            # Scene.from_scene_dict_list(...)ì²˜ëŸ¼ memory ìƒì˜ í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜

            scenario = NavSimScenario(scene, map_root=os.environ["NUPLAN_MAPS_ROOT"], map_version="nuplan-maps-v1.0")

            return processor.compute_and_save_metric_cache(scenario)
            #         ğŸ§  ì™œ ë”°ë¡œ ì²˜ë¦¬í• ê¹Œ?
            # 1. íŒŒì¼ êµ¬ì¡°ê°€ ë‹¤ë¦„
            # - original sceneì€ ë¡œê·¸ ì „ì²´ë¥¼ ë¡œë“œí•˜ê³  ê±°ê¸°ì„œ slicingí•´ì„œ scene ìƒì„±
            # - synthetic sceneì€ ì´ë¯¸ ì™„ì„±ëœ scene ê°ì²´ .pkl.xz íŒŒì¼ë¡œ ì €ì¥ë¨
            # â†’ êµ¬ì¡°ì ìœ¼ë¡œ ë¡œë”© ë°©ì‹ì´ ì™„ì „íˆ ë‹¤ë¦„

            # 2. ë°ì´í„° êµ¬ì„± ì°¨ì´
            # - synthetic sceneì€ ê¸°ì¡´ì— ì—†ë˜ ìƒí™© (ìœ„í—˜ ìƒí™©, ë³´í–‰ì ì¶©ëŒ ë“±)ì„ í•©ì„±í•œ ê²ƒ
            # - ë”°ë¼ì„œ ì‹¤ì œ ë¯¸ë˜ trajectory (GT)ê°€ ì¡´ì¬í•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆìŒ
            # - ì´ ë•Œë¬¸ì— human_trajectory = Noneìœ¼ë¡œ ì²˜ë¦¬

            # 3. êµ¬ë¶„í•´ì„œ ìºì‹œ ê´€ë¦¬
            # - ì‹¤í—˜ì ìœ¼ë¡œë„ original/syntheticì„ ë”°ë¡œ ë¶„ì„í•˜ê±°ë‚˜ ë¹„êµí•´ì•¼ í•˜ë¯€ë¡œ
            # - SceneFrameType.ORIGINAL vs. SYNTHETICë¡œ êµ¬ë¶„í•˜ì—¬ ìºì‹œì— íƒœê·¸ë¥¼ ë¶™ì„

        # 1ï¸âƒ£ ë‚´ë¶€ ì¤€ë¹„
        # args : data_pointsì—ì„œ êº¼ë‚´ì˜¨ ê²ƒ - tokenê³¼ log, hydra ì„¤ì • ë°ì´í„° ì¡´ì¬.
        node_id = int(os.environ.get("NODE_RANK", 0))
        thread_id = str(uuid.uuid4())

        log_names = [a["log_file"] for a in args]
        tokens = [t for a in args for t in a["tokens"]]
        cfg: DictConfig = args[0]["cfg"]
        # ë¶„ì‚° ì‹œìŠ¤í…œì—ì„œ ì–´ë–¤ ë…¸ë“œ/ìŠ¤ë ˆë“œì—ì„œ ì²˜ë¦¬ ì¤‘ì¸ì§€ ì‹ë³„
        # ì²˜ë¦¬í•  ë¡œê·¸ íŒŒì¼ëª…ê³¼ í† í° ëª©ë¡ ìˆ˜ì§‘
        # cfgëŠ” Hydra ì„¤ì • ê°ì²´

        # 2ï¸âƒ£ Scene í•„í„°ë§ ë° ë¡œë”©
        scene_filter: SceneFilter = instantiate(cfg.train_test_split.scene_filter)
        # SceneFilterë¥¼ ì„¤ì •ê°’ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„± - ë§¨ì²˜ìŒ ë„£ì„ë•Œ ë„£ìŒ
        # TRAIN_TEST_SPLIT=navtestìœ¼ë¡œ shíŒŒì¼ì— ë„£ìŒ
        scene_filter.log_names = log_names  # <-- ì›Œì»¤ë§ˆë‹¤ ë…ë¦½ì ì¸ ë¡œê·¸ íŒŒì¼ ëª©ë¡ (ì•ì—ì„œ ì •ì˜í•œ ê²ƒ)
        scene_filter.tokens = tokens  # <-- ì›Œì»¤ë§ˆë‹¤ ë…ë¦½ì ì¸ í† í° ëª©ë¡ (ì•ì—ì„œ ì •ì˜í•œ ê²ƒ)
        scene_loader = SceneLoader(
            synthetic_sensor_path=None,
            original_sensor_path=None,
            data_path=Path(cfg.navsim_log_path),
            synthetic_scenes_path=Path(cfg.synthetic_scenes_path),
            scene_filter=scene_filter,
            sensor_config=SensorConfig.build_no_sensors(),
        )
        # ì•ì—ì„œ ì´ë¯¸ í•œë²ˆ ì •ì˜í–ˆì§€ë§Œ, ë˜ sceneloader ì •ì˜
        # ì´ìœ : ë³‘ë ¬ ì›Œì»¤ë§ˆë‹¤ ë…ë¦½ì ì¸ SceneLoaderê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸
        #   - ê° ì›Œì»¤ëŠ” ìì‹ ì—ê²Œ í• ë‹¹ëœ log_file + tokenë§Œ í•„í„°ë§í•´ì„œ ì²˜ë¦¬í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì„
        #   - ì´ë•Œ ì‚¬ìš©í•˜ëŠ” scene_filter.tokensëŠ” í•´ë‹¹ ì›Œì»¤ ì „ìš© tokenë§Œ í¬í•¨í•˜ë„ë¡ ì„¤ì •ë˜ì–´ ìˆìŒ.

        # 3ï¸âƒ£ MetricCacheProcessor ì¤€ë¹„
        # Create feature preprocessor
        assert cfg.metric_cache_path is not None, f"Cache path cannot be None when caching, got {cfg.metric_cache_path}"
        processor = MetricCacheProcessor(
            cache_path=cfg.metric_cache_path,
            force_feature_computation=cfg.force_feature_computation,
            proposal_sampling=instantiate(cfg.proposal_sampling),
        )
        # ìºì‹œ ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬, ì¬ê³„ì‚° ì—¬ë¶€, trajectory ìƒ˜í”Œë§ ë°©ì‹ ë“± ì´ˆê¸°í™”
        # ì‹¤ì œ ìºì‹±ì„ ë‹´ë‹¹í•˜ëŠ” ì£¼ì²´

        logger.info(f"Extracted {len(scene_loader)} scenarios for thread_id={thread_id}, node_id={node_id}.")
        num_failures = 0
        num_successes = 0
        all_file_cache_metadata: List[Optional[CacheMetadataEntry]] = []
        
        # 4ï¸âƒ£ Original Scene ìºì‹± ë£¨í”„
        # ëŒ€ìƒ : original scene
        # ì„¤ëª… : .pkl ê¸°ë°˜ì˜ ì‹¤ì œ ììœ¨ì£¼í–‰ ë¡œê·¸ì—ì„œ ë‚˜ì˜¨ ì‹œë‚˜ë¦¬ì˜¤
        for idx, scene_dict in enumerate(scene_loader.scene_frames_dicts.values()): # í•˜ë‚˜ì˜ scene ë¶ˆëŸ¬ì˜´
            logger.info(
                f"Processing scenario {idx + 1} / {len(scene_loader.scene_frames_dicts)} in thread_id={thread_id}, node_id={node_id}"
            )
            file_cache_metadata = cache_single_scenario(scene_dict, processor) # í•˜ë‚˜ì˜ scene ìºì‹±
            gc.collect()

            # ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŒ…
            num_failures += 0 if file_cache_metadata else 1
            num_successes += 1 if file_cache_metadata else 0
            all_file_cache_metadata += [file_cache_metadata]

        # 5ï¸âƒ£ Synthetic Scene ìºì‹± ë£¨í”„
        # ëŒ€ìƒ : í•©ì„±(synthetic) scene
        # ì„¤ëª… : ìœ„í—˜ ìƒí™© ë“±ì„ ì¸ìœ„ì ìœ¼ë¡œ ë§Œë“  ì‹œë‚˜ë¦¬ì˜¤
        for idx, (scene_path, _) in enumerate(scene_loader.synthetic_scenes.values()):
            logger.info(
                f"Processing synthetic scenario {idx + 1} / {len(scene_loader.synthetic_scenes)} in thread_id={thread_id}, node_id={node_id}"
            )
            file_cache_metadata = cache_single_synthetic_scenario(scene_path, processor)
            gc.collect()

            # ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŒ…
            num_failures += 0 if file_cache_metadata else 1
            num_successes += 1 if file_cache_metadata else 0
            all_file_cache_metadata += [file_cache_metadata]

        # 6ï¸âƒ£ ìºì‹œ ê²°ê³¼ ìˆ˜ì§‘ ë° ë°˜í™˜
        logger.info(f"Finished processing scenarios for thread_id={thread_id}, node_id={node_id}")
        return [
            CacheResult(
                failures=num_failures,
                successes=num_successes,
                cache_metadata=all_file_cache_metadata,
            )
        ]
    # ì„±ê³µ/ì‹¤íŒ¨ ê°œìˆ˜, ìºì‹œëœ ë©”íƒ€ë°ì´í„° ëª©ë¡ì„ ë‹´ì€ CacheResult ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

    result = cache_scenarios_internal(args)

    # Force a garbage collection to clean up any unused resources
    gc.collect()
# ë‚´ë¶€ í•¨ìˆ˜ê°€ ëë‚œ ë’¤ ìŠ¤ì½”í”„ ì „ì²´ê°€ ì¢…ë£Œë˜ë¯€ë¡œ,
# ë‚´ë¶€ì—ì„œ ìƒì„±ëœ í° ê°ì²´ë“¤(SceneLoader, Scene, NavSimScenario ë“±)ì´ ì™„ì „íˆ í•´ì œë  ìˆ˜ ìˆìŒ

# ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ì— gc.collect()ë¥¼ í˜¸ì¶œí•´ì„œ ìˆ˜ë™ìœ¼ë¡œ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ì„ ê°•ì œ ì‹¤í–‰í•©ë‹ˆë‹¤.


    # ì‹¤ì œë¡œëŠ” cache_scenarios() ì•ˆì— ë˜ cache_scenarios_internal()ì„ 
    # ì¤‘ì²© í•¨ìˆ˜(nested function)ë¡œ ì •ì˜í•¨

# cache_scenarios() ë‚´ë¶€ì— cache_scenarios_internal()ì„ ë‘” ê±´
# **â€œë³‘ë ¬ í™˜ê²½ì—ì„œ ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì—†ì´ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ê³„â€**ì…ë‹ˆë‹¤.

# ì´ê±´ Pythonì—ì„œ ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬ ì‹œ ê½¤ í”í•œ ê³ ê¸‰ í…Œí¬ë‹‰ì´ì—ìš”.

    return result


def cache_data(cfg: DictConfig, worker: WorkerPool) -> None:
    """
    Build the lightning datamodule and cache all samples.
    :param cfg: omegaconf dictionary
    :param worker: Worker to submit tasks which can be executed in parallel
    """
    # SceneLoaderë¡œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜´ â†’ ì‹œë‚˜ë¦¬ì˜¤ë³„ë¡œ ìª¼ê°¬
    # ê° ì‹œë‚˜ë¦¬ì˜¤ë¥¼ workerë¥¼ í†µí•´ ë³‘ë ¬ ì²˜ë¦¬ â†’ cache_scenarios()ì— ë„˜ê¹€
    # ê° ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ MetricCacheProcessorë¥¼ ì´ìš©í•´ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•˜ê³  ì €ì¥
    # ìºì‹± ì„±ê³µ/ì‹¤íŒ¨ ì •ë³´ë¥¼ ì¢…í•©í•´ ë¡œê·¸ë¡œ ì¶œë ¥ + ë©”íƒ€ë°ì´í„° CSVë¡œ ì €ì¥

    assert cfg.metric_cache_path is not None, f"Cache path cannot be None when caching, got {cfg.metric_cache_path}"

    # Extract scenes based on scene-loader to know which tokens to distribute across workers
    # TODO: infer the tokens per log from metadata, to not have to load metric cache and scenes here

    # 1ï¸âƒ£ SceneLoader ì´ˆê¸°í™”
    scene_loader = SceneLoader(
        synthetic_sensor_path=None,
        original_sensor_path=None,
        data_path=Path(cfg.navsim_log_path),
        synthetic_scenes_path=Path(cfg.synthetic_scenes_path),
        scene_filter=instantiate(cfg.train_test_split.scene_filter),
        sensor_config=SensorConfig.build_no_sensors(),
    )
    # SceneLoaderëŠ” .pkl ë¡œê·¸ ë°ì´í„°ë¥¼ ë¡œë“œí•´ì„œ scene ë‹¨ìœ„ë¡œ ë‚˜ëˆ”.
    # scene_filterì— ë”°ë¼ ì¡°ê±´(ì˜ˆ: í”„ë ˆì„ ìˆ˜, ê²½ë¡œ í¬í•¨ ì—¬ë¶€ ë“±)ì„ ë§Œì¡±í•˜ëŠ” sceneë§Œ í•„í„°ë§.
    # ì›ë³¸(scene_frames_dicts)ê³¼ í•©ì„±(synthetic_scenes) ë‘˜ ë‹¤ ì²˜ë¦¬ ê°€ëŠ¥.

    # 2ï¸âƒ£ ì‘ì—… ë¶„í•  (token ê¸°ì¤€)
    data_points = [
        {
            "cfg": cfg,
            "log_file": log_file,
            "tokens": tokens_list,
        }
        for log_file, tokens_list in scene_loader.get_tokens_list_per_log().items()
    ]
    # ê° log íŒŒì¼ë³„ë¡œ í¬í•¨ëœ scene token ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ , 
    # ì´ token ë‹¨ìœ„ë¡œ ë³‘ë ¬ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ data_points ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¦.

    # 3ï¸âƒ£ ë³‘ë ¬ ìºì‹± ì‹¤í–‰
    logger.info("Starting metric caching of %s files...", str(len(data_points)))

    # 4ï¸âƒ£ ë‚´ë¶€ì ìœ¼ë¡œ ìºì‹±ë˜ëŠ” ë‚´ìš© (í•µì‹¬) - cache_scenariosí•¨ìˆ˜
    cache_results = worker_map(worker, cache_scenarios, data_points)
    # Rayë‚˜ multiprocessing ê¸°ë°˜ ì›Œì»¤ë¥¼ í†µí•´ cache_scenarios()ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰.
    # ê° ì‘ì—…ì€ Sceneì„ ë¡œë”©í•˜ê³  â†’ NavSimScenarioë¡œ ê°ì‹¸ê³  â†’ MetricCacheProcessorë¡œ ìºì‹±.

    num_success = sum(result.successes for result in cache_results)
    num_fail = sum(result.failures for result in cache_results)
    num_total = num_success + num_fail
    if num_fail == 0:
        logger.info(
            "Completed dataset caching! All %s features and targets were cached successfully.",
            str(num_total),
        )
    else:
        logger.info(
            "Completed dataset caching! Failed features and targets: %s out of %s",
            str(num_fail),
            str(num_total),
        )

    # 5ï¸âƒ£ ë©”íƒ€ë°ì´í„° ê¸°ë¡
    cached_metadata = [
        cache_metadata_entry
        for cache_result in cache_results
        for cache_metadata_entry in cache_result.cache_metadata
        if cache_metadata_entry is not None
    ]
    # ìºì‹œê°€ ì„±ê³µí•œ ì‹œë‚˜ë¦¬ì˜¤ë“¤ì˜ ë©”íƒ€ë°ì´í„°(csv)ê°€ metric_cache_path/metadata/ì— ì €ì¥ë¨.
    # ì´ csv íŒŒì¼ì€ ì´í›„ í•™ìŠµ ë˜ëŠ” í‰ê°€ ë•Œ ì–´ë–¤ ë°ì´í„°ê°€ ìœ íš¨í•œì§€ í•„í„°ë§í•  ë•Œ ì‚¬ìš©.

    node_id = int(os.environ.get("NODE_RANK", 0))
    logger.info(f"Node {node_id}: Storing metadata csv file containing cache paths for valid features and targets...")
    save_cache_metadata(cached_metadata, Path(cfg.metric_cache_path), node_id)
    logger.info("Done storing metadata csv file.")

    # ìµœì¢… ìºì‹œ íŒŒì¼ êµ¬ì¡°
    # metric_cache/
    # â”œâ”€â”€ metadata/
    # â”‚   â””â”€â”€ cache_node_0.csv  â† ì–´ë–¤ sceneë“¤ì´ ì„±ê³µì ìœ¼ë¡œ ìºì‹±ëëŠ”ì§€ ê¸°ë¡
    # â”œâ”€â”€ token_xxxxxxxxxx.pkl.xz  â† MetricCache ê°ì²´ (scene ë‹¨ìœ„ ìºì‹œ)
    # â”œâ”€â”€ token_yyyyyyyyyy.pkl.xz
...
